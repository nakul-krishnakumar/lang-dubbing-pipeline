{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakul-krishnakumar/lang-dubbing-pipeline/blob/main/nakul_sarvam_assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi8KWqViGgMn"
      },
      "source": [
        "# ENGLISH TO MALAYALAM AUDIO DUBBING PIPELINE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjTjwmBrGo1O"
      },
      "source": [
        "## Installation & Setup of Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb_y5vkcYkpS"
      },
      "outputs": [],
      "source": [
        "!pip cache purge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cmm-XxBXZpv_",
        "outputId": "db15e152-87b9-4dc8-ab8a-7fb2402612ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.5.22-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/174.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.5.22-py3-none-any.whl (3.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.5.22\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tvsVPYYCHdn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from IPython.display import Video, Audio, display\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM_uFhFPV9EK"
      },
      "outputs": [],
      "source": [
        "# All file directories\n",
        "FILE_DIR = \"/content\"\n",
        "INPUT_VIDEO_PATH = os.path.join(FILE_DIR, \"input_data/input_video.mp4\")\n",
        "INPUT_AUDIO_PATH = os.path.join(FILE_DIR, \"input_data/input_audio.wav\")\n",
        "PREPROC_PATH = os.path.join(FILE_DIR, \"preprocessed_audio\")\n",
        "PREPROC_VOCALS_PATH = os.path.join(FILE_DIR, \"preprocessed_audio/vocals.wav\")\n",
        "PREPROC_ACCOMP_PATH = os.path.join(FILE_DIR, \"preprocessed_audio/accompaniment.wav\")\n",
        "TRANS_TEXT_PATH = os.path.join(FILE_DIR, \"text_data\")\n",
        "OUTPUT_AUDIO_PATH = os.path.join(FILE_DIR, \"output_data\")\n",
        "OUTPUT_AUDIO_FILE = os.path.join(OUTPUT_AUDIO_PATH, \"output_audio.wav\")\n",
        "RAW_OUTPUT_AUDIO_FILE = os.path.join(OUTPUT_AUDIO_PATH, \"raw_output_audio.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbmx18elG9fA"
      },
      "source": [
        "## Downloading the Source Video from Youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWe0HVYHZouZ",
        "outputId": "64be43f9-9859-4206-8c92-acda572a3128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=eMc2dRfYZuE\n",
            "[youtube] eMc2dRfYZuE: Downloading webpage\n",
            "[youtube] eMc2dRfYZuE: Downloading tv client config\n",
            "[youtube] eMc2dRfYZuE: Downloading player 59b252b9-main\n",
            "[youtube] eMc2dRfYZuE: Downloading tv player API JSON\n",
            "[youtube] eMc2dRfYZuE: Downloading ios player API JSON\n",
            "[youtube] eMc2dRfYZuE: Downloading m3u8 information\n",
            "[info] eMc2dRfYZuE: Downloading 1 format(s): 625+140\n",
            "[hlsnative] Downloading m3u8 manifest\n",
            "[hlsnative] Total fragments: 50\n",
            "[download] Destination: input_data/input_video.f625.mp4\n",
            "\u001b[K[download] 100% of  209.87MiB in \u001b[1;37m00:00:15\u001b[0m at \u001b[0;32m13.64MiB/s\u001b[0m\n",
            "[download] Destination: input_data/input_video.f140.m4a\n",
            "\u001b[K[download] 100% of    4.07MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m7.87MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"input_data/input_video.mp4\"\n",
            "Deleting original file input_data/input_video.f625.mp4 (pass -k to keep)\n",
            "Deleting original file input_data/input_video.f140.m4a (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "!yt-dlp -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]' -o \"input_data/input_video.mp4\" \"https://www.youtube.com/watch?v=eMc2dRfYZuE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ9as8-EOunE",
        "outputId": "c3819486-b34f-44f8-ac24-bddcec1f8ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uT1hQdHh9SC",
        "outputId": "4c006ca4-7e18-4f99-edc6-b896762482e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34minput_data\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "JQd7BdF4qGkh",
        "outputId": "94463902-321f-455a-a6e9-b77260ba89f8"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/input_data/input_video.mp4'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 18] Invalid cross-device link: '/content/drive/MyDrive/input_data/input_video.mp4' -> '/content/input_data/input_video.mp4'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-88b3e4b2e47c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Move the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/input_data/input_video.mp4'"
          ]
        }
      ],
      "source": [
        "# If yt-dlp does not work, use shutil to move the input video from drive to working directory\n",
        "import shutil\n",
        "\n",
        "# Paths\n",
        "source_path = \"/content/drive/MyDrive/input_data/input_video.mp4\"\n",
        "destination_path = \"/content/input_data/input_video.mp4\"\n",
        "\n",
        "os.makedirs(\"input_data\", exist_ok=True)\n",
        "# Move the file\n",
        "shutil.move(source_path, destination_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdus_o_FbKmI"
      },
      "outputs": [],
      "source": [
        "# Function to check if a file exists at a given path\n",
        "def do_file_exists(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        print(\"Input video exists at: \", file_path)\n",
        "    else:\n",
        "        print(\"Input video does not exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1WBjOm_LEvX",
        "outputId": "40983df6-48b2-4bd7-bae9-ddd4a92bbed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input video exists at:  /content/input_data/input_video.mp4\n"
          ]
        }
      ],
      "source": [
        "do_file_exists(INPUT_VIDEO_PATH) # Check if the input video exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js2NWk-zd4Om"
      },
      "outputs": [],
      "source": [
        "# Display the input video\n",
        "Video(INPUT_VIDEO_PATH, width=640, height=360, embed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5q1vREBHJrZ"
      },
      "source": [
        "## Extracting Audio from the Source Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "oG3OsL7Yih0U",
        "outputId": "d01019fd-3ed1-4d48-c076-72bd2ce0bf63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_data/input_video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:04:23.83, start: 0.000000, bitrate: 6804 kb/s\n",
            "  Stream #0:0(und): Video: vp9 (Profile 0) (vp09 / 0x39307076), yuv420p(tv, bt709), 3840x2160, 6672 kb/s, 25 fps, 25 tbr, 16k tbn, 16k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 05/22/2025.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'input_data/input_audio.wav':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=    8245kB time=00:04:23.82 bitrate= 256.0kbits/s speed= 291x    \n",
            "video:0kB audio:8245kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000924%\n"
          ]
        }
      ],
      "source": [
        "# # Extracting audio from the input video\n",
        "!ffmpeg -i input_data/input_video.mp4 -ac 1 -ar 16000 -vn input_data/input_audio.wav -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MKrMWF2eor9b",
        "outputId": "1b0ab1bc-bfb9-4dea-8473-cae12c2cc758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input video exists at:  /content/input_data/input_audio.wav\n"
          ]
        }
      ],
      "source": [
        "# Check if the converted audio file exists\n",
        "do_file_exists(INPUT_AUDIO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JINRoAvelPF"
      },
      "outputs": [],
      "source": [
        "# Display the extracted audio\n",
        "Audio(INPUT_AUDIO_PATH, autoplay=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_kTCInnJU2a"
      },
      "source": [
        "## Splitting the Audio into Vocals & BGM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GqvyDYrQWklf"
      },
      "outputs": [],
      "source": [
        "!pip install spleeter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fCj4dYVikKcV"
      },
      "outputs": [],
      "source": [
        "from spleeter.separator import Separator\n",
        "\n",
        "def sep_audio_vocals(input_audio_path, output_dir):\n",
        "    \"\"\"\n",
        "    This function is used to separate the vocals and accompaniment from the input audio\n",
        "\n",
        "    Args:\n",
        "    input_audio_path: Path to the input audio file\n",
        "    output_dir: Directory where the separated audio files will be saved\n",
        "    \"\"\"\n",
        "    # Initialize with 2 stems (vocals + accompaniment)\n",
        "    separator = Separator('spleeter:2stems')\n",
        "\n",
        "    # Process the extracted audio file\n",
        "    separator.separate_to_file(\n",
        "        input_audio_path,\n",
        "        output_dir,\n",
        "        filename_format='{instrument}.{codec}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGAr1HYCTR0t"
      },
      "outputs": [],
      "source": [
        "os.makedirs(PREPROC_PATH, exist_ok=True)\n",
        "\n",
        "sep_audio_vocals(INPUT_AUDIO_PATH, PREPROC_PATH) # separate vocals and accompaniments from input audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP0Tfv1QpgZk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "# Display separated tracks\n",
        "display(\n",
        "    Audio(PREPROC_VOCALS_PATH, autoplay=False),\n",
        "    Audio(PREPROC_ACCOMP_PATH, autoplay=False)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5ihcQm-8ptI"
      },
      "source": [
        "## Speech-to-Text Conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmHhV96KWbW8"
      },
      "source": [
        "### Using AssemblyAI SpeechModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VPT3gRtY8n4m",
        "outputId": "3dec325b-d685-48d1-e52a-2b0b52838f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: assemblyai in /usr/local/lib/python3.11/dist-packages (0.40.2)\n",
            "Requirement already satisfied: httpx>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (0.19.0)\n",
            "Requirement already satisfied: pydantic>=1.10.17 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (4.13.2)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from assemblyai) (15.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (3.4.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (1.3.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx>=0.19.0->assemblyai) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from httpx>=0.19.0->assemblyai) (0.13.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.17->assemblyai) (0.4.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx>=0.19.0->assemblyai) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.11/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx>=0.19.0->assemblyai) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx>=0.19.0->assemblyai) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install assemblyai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0MiMcKg8U9c",
        "outputId": "a7575918-81fe-42d2-9db8-2040e78525d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "Full Transcript: \n",
            "\n",
            "Language is a unique fingerprint of a culture, right? So when we were thinking about AI for Bharat, we were really genuinely thinking, what is AI for Bharat? And a computer vision algorithm will also have to be optimized for images in India. But the customization that you need for languages is significantly higher. The origin story is quite interesting because this was the time when deep learning was taking off. It was sort of like the previous generation of AI. this one being generative AI. And we started teaching courses on deep learning together. We realized that the area is moving from being somewhat theoretically driven to being more practically driven, doing things at scale, building out these models was interesting. So we started teaching. We got a lot of people who were interested to then build this out practically. And that's when the idea of AI for Bharat started, right? So let's build these systems for real. Often they require a lot of investment, so we put in some of our money, bootstrapped it, and just got going. And it evolved interestingly. Initially we started thinking of many, many use cases. I remember students in IIT Madras putting cameras on helmets and doing some computer vision. There were other people doing other things. Then we realized we need a focus, and we chose to focus on Indian languages, given how important it is for us. in a very multilingualistic country and we chose to build out models for translation. And somehow few things we did, a bunch of students, their work sort of strung together and we built translation models in the open source which were competitive or even better than closed source offerings from big tech companies. India is probably the largest consumer of English language content globally. In some sense, We are very diverse. We do the English stuff that we benefit from the English language models, but we have a large population which is also interested in Indian language content. If you look at the numbers of Indian language news channels, their viewership, it's pretty large. We still have many surviving Indian language print newspapers. So the languages continue to survive, but they always need to be updated to the latest technology. So in this case, we were missing technologies that are required to bring these languages and interface them with the evolving AI landscape. So that really was the opportunity. There is a lot of innovation to be done at the use case layer, which is how do we make the models which are good on their raw performance useful for a user? And I think that's where most of the innovation that is private funded, that is use case oriented needs to happen. and the deeper layers they can become sort of building blocks. I think one of the key things is providing greater belief to more people that they can build on top of these layers. So imagine a developer or a small startup thinking, hey, let's add a voice system to our app. Their ability to do that and succeed if their open source components becomes much larger. So I think there's also this collective belief in the country that we could do that. And I think that's important because creating a talent pool that is able to build and build for India becomes critical as we go along. We are living in a country where we are surrounded by problems, right? And many of them could be solved with generative AI, not all, but large fraction, whether it's access to information, access to education, sometimes initial help in healthcare, et cetera. I think there's a lot we could do in the country as we adopt generative AI. I think India needs to have the belief that we are a large player in this. And part of that is the ability to train your models from scratch. I think that's a necessary prerequisite to have the talent pool in the country to do it. At the same time, leverage any existing model, commercial, open source, etc. But a key component I see and I think the work done by AIF, Bharat and various government efforts, I think that is outstanding, is to provide the energy in the ecosystem for more people to become builders of this technology, of this technology, right? I think that's the only way. If we have Indian platforms, Indian entrepreneurs building on top of it, we'll have a critical mass to go after it. But I'm super bullish that India will lead the wave in adopting this technology.\n"
          ]
        }
      ],
      "source": [
        "import assemblyai as aai\n",
        "\n",
        "aai.settings.api_key = userdata.get(\"ASSEMBLY_AI_API_KEY\")\n",
        "\n",
        "transcriber = aai.Transcriber()\n",
        "\n",
        "config = aai.TranscriptionConfig(speech_model=aai.SpeechModel.slam_1)\n",
        "\n",
        "transcript = transcriber.transcribe(PREPROC_VOCALS_PATH, config)\n",
        "\n",
        "if transcript.status == aai.TranscriptStatus.error:\n",
        "    print(f\"Transcription failed: {transcript.error}\")\n",
        "    exit(1)\n",
        "\n",
        "print(f\" \\nFull Transcript: \\n\\n{transcript.text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM_mT_PEDput"
      },
      "outputs": [],
      "source": [
        "stt_text = transcript.text\n",
        "\n",
        "os.makedirs(TRANS_TEXT_PATH, exist_ok=True)\n",
        "with open(os.path.join(TRANS_TEXT_PATH, \"stt_text.txt\"), \"w\") as f:\n",
        "    f.write(stt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpjo9u7lFgKw"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(TRANS_TEXT_PATH, \"stt_text.txt\"), \"r\") as f:\n",
        "    stt_text = f.read()\n",
        "\n",
        "# pprint(stt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_us4-nSKG2px"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(stt_text):\n",
        "    \"\"\"\n",
        "    This function is used to do manual text preprocessing for better audio output.\n",
        "    \"\"\"\n",
        "    sentences = re.findall(r'[^.!?;]+[.!?;]?', stt_text)\n",
        "\n",
        "    preproc_sent = []\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.replace(\"AI for Bharat\", \"AI4Bharat\")\n",
        "\n",
        "        preproc_sent.append(sentence)\n",
        "\n",
        "    return preproc_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16I3J36YNASF"
      },
      "outputs": [],
      "source": [
        "sentences = preprocess_text(stt_text)\n",
        "# sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAwBYKItxNkc"
      },
      "source": [
        "### Using Sarvam Batch API ( Did not convert all the words, missed some )\n",
        "I had tried Batch API first, but it simply ignores some words and the sentences at the end of some of the transcripts.\n",
        "You can refer the outputs of the below codeblocks to notice it.\n",
        "Note the last transcript entry where the transcription is only till 'become' but there is more audio to be transcripted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d9yDXjw5AlpK",
        "outputId": "e063e325-4c0c-4494-c3f1-404602dfa00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (1.5.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting azure-storage-file-datalake\n",
            "  Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (3.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting azure-core>=1.30.0 (from azure-storage-file-datalake)\n",
            "  Downloading azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.25.1 (from azure-storage-file-datalake)\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-storage-file-datalake) (4.13.2)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-file-datalake)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-storage-file-datalake) (1.17.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from azure-storage-blob>=12.25.1->azure-storage-file-datalake) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.25.1->azure-storage-file-datalake) (2.22)\n",
            "Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, aiofiles, azure-core, azure-storage-blob, azure-storage-file-datalake\n",
            "Successfully installed aiofiles-24.1.0 azure-core-1.34.0 azure-storage-blob-12.25.1 azure-storage-file-datalake-12.20.0 isodate-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install requests pandas pydub\n",
        "!pip install azure-storage-file-datalake aiofiles aiohttp requests # for batch-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRhFf0mt1w2p"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import aiofiles\n",
        "import requests\n",
        "import json\n",
        "from urllib.parse import urlparse\n",
        "from azure.storage.filedatalake.aio import DataLakeDirectoryClient, FileSystemClient\n",
        "from azure.storage.filedatalake import ContentSettings\n",
        "import mimetypes\n",
        "import logging\n",
        "from pprint import pprint\n",
        "import os\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration\n",
        "API_SUBSCRIPTION_KEY = userdata.get(\"SARVAM_SUBSCRIPTION_KEY\")\n",
        "LANGUAGE_CODE = \"en-IN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNSoCM866Z1z"
      },
      "outputs": [],
      "source": [
        "class SarvamClient:\n",
        "    def __init__(self, url: str):\n",
        "        self.account_url, self.file_system_name, self.directory_name, self.sas_token = (\n",
        "            self._extract_url_components(url)\n",
        "        )\n",
        "        self.lock = asyncio.Lock()\n",
        "        print(f\"Initialized SarvamClient with directory: {self.directory_name}\")\n",
        "\n",
        "    def update_url(self, url: str):\n",
        "        self.account_url, self.file_system_name, self.directory_name, self.sas_token = (\n",
        "            self._extract_url_components(url)\n",
        "        )\n",
        "        print(f\"Updated URL to directory: {self.directory_name}\")\n",
        "\n",
        "    def _extract_url_components(self, url: str):\n",
        "        parsed_url = urlparse(url)\n",
        "        account_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\".replace(\n",
        "            \".blob.\", \".dfs.\"\n",
        "        )\n",
        "        path_components = parsed_url.path.strip(\"/\").split(\"/\")\n",
        "        file_system_name = path_components[0]\n",
        "        directory_name = \"/\".join(path_components[1:])\n",
        "        sas_token = parsed_url.query\n",
        "        return account_url, file_system_name, directory_name, sas_token\n",
        "\n",
        "    async def upload_files(self, local_file_paths, overwrite=True):\n",
        "        print(f\"Starting upload of {len(local_file_paths)} files\")\n",
        "        async with DataLakeDirectoryClient(\n",
        "            account_url=f\"{self.account_url}?{self.sas_token}\",\n",
        "            file_system_name=self.file_system_name,\n",
        "            directory_name=self.directory_name,\n",
        "            credential=None,\n",
        "        ) as directory_client:\n",
        "            tasks = []\n",
        "            for path in local_file_paths:\n",
        "                file_name = path.split(\"/\")[-1]\n",
        "                tasks.append(\n",
        "                    self._upload_file(directory_client, path, file_name, overwrite)\n",
        "                )\n",
        "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "            print(\n",
        "                f\"Upload completed for {sum(1 for r in results if not isinstance(r, Exception))} files\"\n",
        "            )\n",
        "\n",
        "    async def _upload_file(\n",
        "        self, directory_client, local_file_path, file_name, overwrite=True\n",
        "    ):\n",
        "        try:\n",
        "            async with aiofiles.open(local_file_path, mode=\"rb\") as file_data:\n",
        "                mime_type = mimetypes.guess_type(local_file_path)[0] or \"audio/wav\"\n",
        "                file_client = directory_client.get_file_client(file_name)\n",
        "                data = await file_data.read()\n",
        "                await file_client.upload_data(\n",
        "                    data,\n",
        "                    overwrite=overwrite,\n",
        "                    content_settings=ContentSettings(content_type=mime_type),\n",
        "                )\n",
        "                print(f\"✅ File uploaded successfully: {file_name}\")\n",
        "                print(f\"   Type: {mime_type}\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Upload failed for {file_name}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    async def list_files(self):\n",
        "        print(\"\\n📂 Listing files in directory...\")\n",
        "        file_names = []\n",
        "        async with FileSystemClient(\n",
        "            account_url=f\"{self.account_url}?{self.sas_token}\",\n",
        "            file_system_name=self.file_system_name,\n",
        "            credential=None,\n",
        "        ) as file_system_client:\n",
        "            async for path in file_system_client.get_paths(self.directory_name):\n",
        "                file_name = path.name.split(\"/\")[-1]\n",
        "                async with self.lock:\n",
        "                    file_names.append(file_name)\n",
        "        print(f\"Found {len(file_names)} files:\")\n",
        "        for file in file_names:\n",
        "            print(f\"   📄 {file}\")\n",
        "        return file_names\n",
        "\n",
        "    async def download_files(self, file_names, destination_dir):\n",
        "        print(f\"\\n⬇️ Starting download of {len(file_names)} files to {destination_dir}\")\n",
        "        async with DataLakeDirectoryClient(\n",
        "            account_url=f\"{self.account_url}?{self.sas_token}\",\n",
        "            file_system_name=self.file_system_name,\n",
        "            directory_name=self.directory_name,\n",
        "            credential=None,\n",
        "        ) as directory_client:\n",
        "            tasks = []\n",
        "            for file_name in file_names:\n",
        "                tasks.append(\n",
        "                    self._download_file(directory_client, file_name, destination_dir)\n",
        "                )\n",
        "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "            print(\n",
        "                f\"Download completed for {sum(1 for r in results if not isinstance(r, Exception))} files\"\n",
        "            )\n",
        "\n",
        "    async def _download_file(self, directory_client, file_name, destination_dir):\n",
        "        try:\n",
        "            file_client = directory_client.get_file_client(file_name)\n",
        "            download_path = f\"{destination_dir}/{file_name}\"\n",
        "            async with aiofiles.open(download_path, mode=\"wb\") as file_data:\n",
        "                stream = await file_client.download_file()\n",
        "                data = await stream.readall()\n",
        "                await file_data.write(data)\n",
        "            print(f\"✅ Downloaded: {file_name} -> {download_path}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Download failed for {file_name}: {str(e)}\")\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3m0d5Xy3R7V"
      },
      "outputs": [],
      "source": [
        "async def initialize_job():\n",
        "    print(\"\\n🚀 Initializing job...\")\n",
        "    url = \"https://api.sarvam.ai/speech-to-text/job/init\"\n",
        "    headers = {\"API-Subscription-Key\": API_SUBSCRIPTION_KEY}\n",
        "    response = requests.post(url, headers=headers)\n",
        "    print(\"\\nInitialize Job Response:\")\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    print(\"Response Body:\")\n",
        "    pprint(response.json() if response.status_code == 202 else response.text)\n",
        "\n",
        "    if response.status_code == 202:\n",
        "        return response.json()\n",
        "    return None\n",
        "\n",
        "\n",
        "async def check_job_status(job_id):\n",
        "    print(f\"\\n🔍 Checking status for job: {job_id}\")\n",
        "    url = f\"https://api.sarvam.ai/speech-to-text/job/{job_id}/status\"\n",
        "    headers = {\"API-Subscription-Key\": API_SUBSCRIPTION_KEY}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    print(\"\\nJob Status Response:\")\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    print(\"Response Body:\")\n",
        "    pprint(response.json() if response.status_code == 200 else response.text)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    return None\n",
        "\n",
        "\n",
        "async def start_job(job_id, language_code=LANGUAGE_CODE):\n",
        "    print(f\"\\n▶️ Starting job: {job_id}\")\n",
        "    url = \"https://api.sarvam.ai/speech-to-text/job\"\n",
        "    headers = {\n",
        "        \"API-Subscription-Key\": API_SUBSCRIPTION_KEY,\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    data = {\"job_id\": job_id, \"job_parameters\": {\n",
        "        \"language_code\": language_code,\n",
        "        \"with_timestamps\": True,\n",
        "        \"with_diarization\": False\n",
        "    }}\n",
        "    print(\"\\nRequest Body:\")\n",
        "    pprint(data)\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
        "    print(\"\\nStart Job Response:\")\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    print(\"Response Body:\")\n",
        "    pprint(response.json() if response.status_code == 200 else response.text)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xegljtCF8z6"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def split_audio_into_chunks(input_audio_path, chunk_duration_ms=3 * 60 * 1000, output_dir=\"chunks\"):\n",
        "    \"\"\"\n",
        "    Splits an audio file into chunks of given duration and saves them to a directory.\n",
        "\n",
        "    input_audio_path: Path to the input audio file\n",
        "    chunk_duration_ms: Duration of each chunk in milliseconds (default 3 minutes)\n",
        "    output_dir: Directory where chunks will be saved\n",
        "\n",
        "    return: List of paths to the chunk files\n",
        "    \"\"\"\n",
        "    audio = AudioSegment.from_file(input_audio_path)\n",
        "    total_length = len(audio)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    chunk_paths = []\n",
        "    for i in range(0, total_length, chunk_duration_ms):\n",
        "        chunk = audio[i:i + chunk_duration_ms]\n",
        "        chunk_filename = os.path.join(output_dir, f\"chunk_{i // chunk_duration_ms + 1}.wav\")\n",
        "        chunk.export(chunk_filename, format=\"wav\")\n",
        "        chunk_paths.append(chunk_filename)\n",
        "        print(f\"Saved: {chunk_filename}\")\n",
        "\n",
        "    print(f\"\\n✅ Total {len(chunk_paths)} chunks created.\")\n",
        "    return chunk_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_WvF-xdKgry"
      },
      "outputs": [],
      "source": [
        "split_audio_into_chunks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUCM43ar24wA"
      },
      "outputs": [],
      "source": [
        "async def main():\n",
        "    print(\"\\n=== Starting Speech-to-Text Processing for All Chunks ===\")\n",
        "\n",
        "    # Step 1: Split the audio into chunks\n",
        "    chunk_paths = split_audio_into_chunks(PREPROC_VOCALS_PATH, output_dir=os.path.join(FILE_DIR, \"preprocessed_audio\"))\n",
        "    print(f\"🔀 Total Chunks Created: {len(chunk_paths)}\")\n",
        "\n",
        "    for idx, chunk_path in enumerate(chunk_paths):\n",
        "        print(f\"\\n=== Processing Chunk {idx + 1}/{len(chunk_paths)}: {os.path.basename(chunk_path)} ===\")\n",
        "\n",
        "        # Step 2: Initialize a new job for this chunk\n",
        "        job_info = await initialize_job()\n",
        "        if not job_info:\n",
        "            print(\"❌ Job initialization failed for this chunk\")\n",
        "            continue\n",
        "\n",
        "        job_id = job_info[\"job_id\"]\n",
        "        input_storage_path = job_info[\"input_storage_path\"]\n",
        "        output_storage_path = job_info[\"output_storage_path\"]\n",
        "\n",
        "        # Step 3: Upload chunk to input storage\n",
        "        client = SarvamClient(input_storage_path)\n",
        "        await client.upload_files([chunk_path])\n",
        "        print(\"📤 Chunk uploaded\")\n",
        "\n",
        "        # Step 4: Wait for job to be ACCEPTED\n",
        "        print(\"⏳ Waiting for job to be ACCEPTED...\")\n",
        "        while True:\n",
        "            job_status = await check_job_status(job_id)\n",
        "            if not job_status:\n",
        "                print(\"❌ Failed to get job status\")\n",
        "                break\n",
        "\n",
        "            if job_status[\"job_state\"] == \"Accepted\":\n",
        "                print(\"✅ Job is now ACCEPTED\")\n",
        "                break\n",
        "            elif job_status[\"job_state\"] == \"Failed\":\n",
        "                print(\"❌ Job failed during validation\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"⏳ Still waiting... Current state: {job_status['job_state']}\")\n",
        "                await asyncio.sleep(5)\n",
        "\n",
        "        # Step 5: Start the job\n",
        "        job_start_response = await start_job(job_id)\n",
        "        if not job_start_response:\n",
        "            print(\"❌ Failed to start job\")\n",
        "            continue\n",
        "        print(\"🚀 Job started\")\n",
        "\n",
        "        # Step 6: Wait for job to COMPLETE\n",
        "        print(\"⏳ Waiting for job to complete...\")\n",
        "        while True:\n",
        "            job_status = await check_job_status(job_id)\n",
        "            if not job_status:\n",
        "                print(\"❌ Failed to get job status\")\n",
        "                break\n",
        "\n",
        "            if job_status[\"job_state\"] == \"Completed\":\n",
        "                print(\"✅ Job completed\")\n",
        "                break\n",
        "            elif job_status[\"job_state\"] == \"Failed\":\n",
        "                print(\"❌ Job failed during execution\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"⏳ Still processing... Current state: {job_status['job_state']}\")\n",
        "                await asyncio.sleep(10)\n",
        "\n",
        "        # Step 7: Download the result\n",
        "        print(f\"📥 Downloading result for Chunk {idx + 1}\")\n",
        "        client.update_url(output_storage_path)\n",
        "\n",
        "        files = await client.list_files()\n",
        "        chunk_result_dir = os.path.join(TRANS_TEXT_PATH, f\"chunk_{idx + 1}\")\n",
        "        os.makedirs(chunk_result_dir, exist_ok=True)\n",
        "\n",
        "        await client.download_files(files, destination_dir=chunk_result_dir)\n",
        "        print(f\"✅ Files downloaded to: {chunk_result_dir}\")\n",
        "\n",
        "    print(\"\\n=== All Chunks Processed ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FyltOmbWwgB"
      },
      "source": [
        "#### Preprocessing Converted Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lugbYgANSHjv"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "chunk1_path = os.path.join(TRANS_TEXT_PATH, \"chunk_1\", \"0.json\")\n",
        "chunk2_path = os.path.join(TRANS_TEXT_PATH, \"chunk_2\", \"0.json\")\n",
        "\n",
        "\n",
        "# Load JSON data from the file\n",
        "with open(chunk1_path, 'r') as f:\n",
        "    chunk1 = json.load(f)\n",
        "\n",
        "with open(chunk2_path, 'r') as f:\n",
        "    chunk2 = json.load(f)\n",
        "\n",
        "pprint(chunk1)\n",
        "pprint(chunk2)\n",
        "\n",
        "# Notice that both the chunks have few errors\n",
        "# chunk1 has an unwanted initial '0.0' entry in both start_time and end_time.\n",
        "# chunk2 has start_time and end_time starting from 0.0, instead they should start from chunk1's last end_time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nknY3OvNOu5n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def refine_text_chunks(chunk1, chunk2):\n",
        "    \"\"\"\n",
        "    This function is used to manually refining the converted text chunks\n",
        "    \"\"\"\n",
        "\n",
        "    # Refine chunk_1\n",
        "    # Remove the first element of start_time_seconds and end_time_seconds\n",
        "    chunk1[\"timestamps\"][\"start_time_seconds\"] = chunk1[\"timestamps\"][\"start_time_seconds\"][1:]\n",
        "    chunk1[\"timestamps\"][\"end_time_seconds\"] = chunk1[\"timestamps\"][\"end_time_seconds\"][1:]\n",
        "\n",
        "    # Refine chunk_2\n",
        "    chunk1_end_time = chunk1[\"timestamps\"][\"end_time_seconds\"][-1]\n",
        "\n",
        "    chunk2[\"timestamps\"][\"start_time_seconds\"] = [\n",
        "        t + chunk1_end_time for t in chunk2[\"timestamps\"][\"start_time_seconds\"]\n",
        "    ]\n",
        "\n",
        "    chunk2[\"timestamps\"][\"end_time_seconds\"] = [\n",
        "        t + chunk1_end_time for t in chunk2[\"timestamps\"][\"end_time_seconds\"]\n",
        "    ]\n",
        "\n",
        "    return chunk1, chunk2\n",
        "\n",
        "def merge_text_chunks(chunk1, chunk2):\n",
        "    \"\"\"\n",
        "    This function is used to merge the refined text chunks into a single list\n",
        "    \"\"\"\n",
        "    ref_chunk1, ref_chunk2 = refine_text_chunks(chunk1, chunk2)\n",
        "\n",
        "    segments = []\n",
        "    for start, end, text in zip(\n",
        "        ref_chunk1[\"timestamps\"][\"start_time_seconds\"],\n",
        "        ref_chunk1[\"timestamps\"][\"end_time_seconds\"],\n",
        "        ref_chunk1[\"timestamps\"][\"words\"]\n",
        "    ):\n",
        "        segments.append({\n",
        "            \"start\": start,\n",
        "            \"end\": end,\n",
        "            \"text\": text,\n",
        "            \"duration\": end - start\n",
        "        })\n",
        "\n",
        "    for start, end, text in zip(\n",
        "        ref_chunk2[\"timestamps\"][\"start_time_seconds\"],\n",
        "        ref_chunk2[\"timestamps\"][\"end_time_seconds\"],\n",
        "        ref_chunk2[\"timestamps\"][\"words\"]\n",
        "    ):\n",
        "        segments.append({\n",
        "            \"start\": start,\n",
        "            \"end\": end,\n",
        "            \"text\": text,\n",
        "            \"duration\": end - start\n",
        "        })\n",
        "\n",
        "    # print(\"============================== SEGMENTS ======================================\")\n",
        "    # pprint(segments)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def preprocess_text(segments):\n",
        "    \"\"\"\n",
        "    This function is used to do manual text preprocessing for better audio output.\n",
        "    \"\"\"\n",
        "    for seg in segments:\n",
        "        seg[\"text\"] = seg[\"text\"].replace(\"AI for Bharat\", \"AI4Bharat\")\n",
        "        seg[\"text\"] = seg[\"text\"].replace(\",\", \" \") # audio generated using bulbulv2 had a weird stop at ','\n",
        "\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WQmXHGSVX9tF"
      },
      "outputs": [],
      "source": [
        "segments = merge_text_chunks(chunk1, chunk2) # merge texts chunks into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5mC5OGzvYN-N"
      },
      "outputs": [],
      "source": [
        "segments = preprocess_text(segments)\n",
        "segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbP35PRkki4w"
      },
      "source": [
        "## Sarvam Client API Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oozNCGJRKwVi",
        "outputId": "3c624c6c-2541-4484-ea74-f27e3dc52ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sarvamai in /usr/local/lib/python3.11/dist-packages (0.1.3)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from sarvamai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from sarvamai) (2.11.4)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from sarvamai) (2.33.2)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from sarvamai) (4.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->sarvamai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->sarvamai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->sarvamai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->sarvamai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->sarvamai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->sarvamai) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->sarvamai) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->sarvamai) (1.3.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx) (1.3.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sarvamai\n",
        "!pip install --upgrade httpx\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au1sWCsSi5wp"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "import base64\n",
        "import io\n",
        "from typing import Dict, List\n",
        "from sarvamai import SarvamAI\n",
        "\n",
        "class SarvamClientAPI():\n",
        "    def __init__(self, api_subscription_key):\n",
        "        self.client = SarvamAI(api_subscription_key=api_subscription_key,)\n",
        "        pass\n",
        "\n",
        "    def translate_text(\n",
        "            self,\n",
        "            sentences,\n",
        "            source_lang: str,\n",
        "            target_lang: str,\n",
        "            gender: str = \"Male\",\n",
        "            mode: str = \"code-mixed\",\n",
        "            output_script: str = \"spoken-form-in-native\",\n",
        "            enable_preprocessing: bool = False\n",
        "        ) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        This function is used to translate the given text from source to target language.\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: A list of dictionaries, where each dictionary includes:\n",
        "        \"\"\"\n",
        "\n",
        "        # English to Malayalam text preprocessing using mayura-api\n",
        "        translated_texts = []\n",
        "        # print(sentences)\n",
        "        for i, sentence in enumerate(sentences):\n",
        "            # print(sentence)\n",
        "            if sentence and sentence.strip():  # skip None or empty/whitespace-only strings\n",
        "                response = self.client.text.translate(\n",
        "                    input=sentence.strip(),  # strip leading/trailing whitespace\n",
        "                    source_language_code=source_lang,\n",
        "                    target_language_code=target_lang,\n",
        "                    speaker_gender=gender,\n",
        "                    mode=mode,\n",
        "                    output_script=output_script,\n",
        "                    enable_preprocessing=enable_preprocessing\n",
        "                )\n",
        "\n",
        "                print(f\"Processed batch {i + 1} ...\")\n",
        "                translated_texts.append(response.translated_text)\n",
        "\n",
        "\n",
        "                # translated_texts.append({\n",
        "                #     \"start\": seg[\"start\"],\n",
        "                #     \"end\": seg[\"end\"],\n",
        "                #     \"text\": response.translated_text,\n",
        "                #     \"duration\": seg['duration']\n",
        "                # })\n",
        "        return translated_texts\n",
        "\n",
        "    def stretch_audio_segment(self, original_duration_sec, audio_response):\n",
        "        \"\"\"\n",
        "        Stretch TTS audio to match original duration.\n",
        "        \"\"\"\n",
        "        # Decode base64 audio\n",
        "        audio_bytes = base64.b64decode(audio_response.audios[0])\n",
        "\n",
        "        # Load audio with soundfile to handle in-memory files\n",
        "        with io.BytesIO(audio_bytes) as bio:\n",
        "            y, sr = sf.read(bio)\n",
        "\n",
        "        # Calculate current TTS duration\n",
        "        tts_duration_sec = len(y) / sr\n",
        "\n",
        "        # Handle zero/negative duration edge cases\n",
        "        if tts_duration_sec <= 0 or original_duration_sec <= 0:\n",
        "            return AudioSegment.silent(duration=original_duration_sec * 1000)\n",
        "\n",
        "        # Compute stretch rate (inverse of RubberBand's approach)\n",
        "        rate = tts_duration_sec / original_duration_sec\n",
        "\n",
        "        # Apply librosa's time_stretch (mono only)\n",
        "        if y.ndim > 1:\n",
        "            y = librosa.to_mono(y.T)\n",
        "\n",
        "        y_stretched = librosa.effects.time_stretch(y, rate=rate)\n",
        "\n",
        "        # Convert back to AudioSegment\n",
        "        with io.BytesIO() as output_bio:\n",
        "            sf.write(output_bio, y_stretched, sr, format='WAV')\n",
        "            output_bio.seek(0)\n",
        "            return AudioSegment.from_wav(output_bio)\n",
        "\n",
        "    def convert_text_to_speech(\n",
        "            self,\n",
        "            texts,\n",
        "            target_language_code,\n",
        "            model: str =\"bulbul:v2\",\n",
        "            speaker: str =\"karun\",\n",
        "            pitch: int = 0.1,\n",
        "            pace: int = 1.0,\n",
        "            loudness: int = 1.0,\n",
        "            speech_sample_rate: str = 24000,\n",
        "            enable_preprocessing: bool = True\n",
        "        ):\n",
        "\n",
        "        \"\"\"\n",
        "        This function is used to convert the given text to target language audio\n",
        "\n",
        "        Return:\n",
        "            combined_stretched_audio : Audio segment where each portion has been time-stretched to match its target duration.\n",
        "            raw_audio : Concatenated raw audio output directly from the TTS engine.\n",
        "        \"\"\"\n",
        "\n",
        "        combined_stretched_audio = AudioSegment.empty()\n",
        "        raw_audio = AudioSegment.empty()\n",
        "\n",
        "        for i, text in enumerate(texts):\n",
        "            # # Set parameters based on text content\n",
        "            # if \"!\" in text:\n",
        "            #     # Exclamation: higher pitch, faster pace, louder\n",
        "            #     pitch = 0.2\n",
        "            #     pace = 1.0\n",
        "            #     loudness = 1.2\n",
        "            # elif \"?\" in text:\n",
        "            #     # Question: slightly higher pitch, slower pace\n",
        "            #     pitch = 0.1\n",
        "            #     pace = 0.7\n",
        "            #     loudness = 1.0\n",
        "            # else:\n",
        "            #     # Neutral/default\n",
        "            #     pitch = -0.1\n",
        "            #     pace = 0.8\n",
        "            #     loudness = 1.0\n",
        "\n",
        "            audio = self.client.text_to_speech.convert(\n",
        "                text=text,\n",
        "                target_language_code=target_language_code,\n",
        "                model=model,\n",
        "                speaker=speaker,\n",
        "                pitch=pitch,\n",
        "                pace=pace,\n",
        "                loudness=loudness,\n",
        "                speech_sample_rate=speech_sample_rate,\n",
        "                enable_preprocessing=enable_preprocessing\n",
        "            )\n",
        "\n",
        "            audio_segment = AudioSegment.from_file(io.BytesIO(base64.b64decode(audio.audios[0])), format=\"wav\")\n",
        "            raw_audio += audio_segment\n",
        "\n",
        "            # stretched_audio = self.stretch_audio_segment(seg['duration'], audio)\n",
        "            # combined_stretched_audio += stretched_audio\n",
        "            print(f\"Processed batch {i + 1}\")\n",
        "\n",
        "        return combined_stretched_audio, raw_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB1gK0jDUOTr"
      },
      "outputs": [],
      "source": [
        "API_SUBSCRIPTION_KEY = userdata.get(\"SARVAM_SUBSCRIPTION_KEY\")\n",
        "\n",
        "client = SarvamClientAPI(API_SUBSCRIPTION_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTGsNoQvW7j7"
      },
      "source": [
        "## English-to-Malayalam Text Translation using Sarvam Mayura API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK_z3waQfTYr",
        "outputId": "a9b7c23a-f008-4afd-89b6-6090deea078c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1 ...\n",
            "Processed batch 2 ...\n",
            "Processed batch 3 ...\n",
            "Processed batch 4 ...\n",
            "Processed batch 5 ...\n",
            "Processed batch 6 ...\n",
            "Processed batch 7 ...\n",
            "Processed batch 8 ...\n",
            "Processed batch 9 ...\n",
            "Processed batch 10 ...\n",
            "Processed batch 11 ...\n",
            "Processed batch 12 ...\n",
            "Processed batch 13 ...\n",
            "Processed batch 14 ...\n",
            "Processed batch 15 ...\n",
            "Processed batch 16 ...\n",
            "Processed batch 17 ...\n",
            "Processed batch 18 ...\n",
            "Processed batch 19 ...\n",
            "Processed batch 20 ...\n",
            "Processed batch 21 ...\n",
            "Processed batch 22 ...\n",
            "Processed batch 23 ...\n",
            "Processed batch 24 ...\n",
            "Processed batch 25 ...\n",
            "Processed batch 26 ...\n",
            "Processed batch 27 ...\n",
            "Processed batch 28 ...\n",
            "Processed batch 29 ...\n",
            "Processed batch 30 ...\n",
            "Processed batch 31 ...\n",
            "Processed batch 32 ...\n",
            "Processed batch 33 ...\n",
            "Processed batch 34 ...\n",
            "Processed batch 35 ...\n",
            "Processed batch 36 ...\n",
            "Processed batch 37 ...\n",
            "Processed batch 38 ...\n",
            "Processed batch 39 ...\n",
            "Processed batch 40 ...\n",
            "Processed batch 41 ...\n",
            "Processed batch 42 ...\n",
            "Processed batch 43 ...\n",
            "Processed batch 44 ...\n",
            "Processed batch 45 ...\n",
            "Processed batch 46 ...\n",
            "Processed batch 47 ...\n",
            "Processed batch 48 ...\n"
          ]
        }
      ],
      "source": [
        "translated_texts = client.translate_text(\n",
        "    sentences,\n",
        "    source_lang=\"en-IN\",\n",
        "    target_lang=\"ml-IN\",\n",
        "    gender=\"Male\",\n",
        "    mode=\"code-mixed\",\n",
        "    output_script=\"spoken-form-in-native\",\n",
        "    enable_preprocessing=True\n",
        ")\n",
        "\n",
        "# pprint(translated_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G-cfYhLc3_fd",
        "outputId": "a8e1888f-3cc1-4722-aacc-a1f5f4fae91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ഒരു കൾച്ചറിൻ്റെ യുണിക് ഫിംഗർപ്രിൻ്റ് ആണ് ലാംഗ്വേജ്, അല്ലേ?',\n",
              " 'അപ്പോൾ ഞങ്ങൾ എ ഐ ഫോർ ഭാരത് കൺസിഡർ ചെയ്യുമ്പോൾ, എ ഐ ഫോർ ഭാരത് എന്താണെന്ന് സീരിയസ്ലി ആയിട്ട് ആലോചിച്ചു.',\n",
              " 'ഇന്ത്യയിൽ നിന്നുള്ള ഇമേജസുമായി നന്നായി പ്രവർത്തിക്കാൻ ഒരു കമ്പ്യൂട്ടർ വിഷൻ അൽഗോരിതം അഡ്ജസ്റ്റ് ചെയ്യേണ്ടി വരും.',\n",
              " 'പക്ഷേ ലാംഗ്വേജസിന് വേണ്ടി താങ്കൾ കൂടുതൽ ചേഞ്ചസ് വരുത്തേണ്ടതുണ്ട്.',\n",
              " 'ഡീപ് ലേണിങ് എങ്ങനെ പോപ്പുലർ ആയി എന്നുള്ള കഥ വളരെ ഫാസിനറ്റിങ് ആണ്. ഡീപ് ലേണിങ് മൊമെന്റം നേടുന്ന ഒരു സമയത്തായിരുന്നു അത്.',\n",
              " 'അത് മുൻപത്തെ എ ഐ ജനറേഷനോട് സമാനമായിരുന്നു.',\n",
              " 'ഇത് ജനറേറ്റീവ് എ ഐ ആണ്.',\n",
              " 'പിന്നെ ഞങ്ങൾ ഡീപ് ലേണിങ്ങിൽ കോഴ്സസ് ഒന്നിച്ച് പഠിപ്പിക്കാൻ തുടങ്ങി.',\n",
              " 'ഈ ഏരിയ മെയിൻലി തിയററ്റിക്കൽ ആയിരുന്നത് ഇപ്പോൾ പ്രാക്ടിക്കൽ ആപ്ലിക്കേഷനുകളിൽ കൂടുതൽ ഫോക്കസ് ചെയ്യുന്നു എന്നാണല്ലോ ഞങ്ങൾ ശ്രദ്ധിച്ചത്. ഈ ഷിഫ്റ്റിൽ ലാർജ് സ്കെയിലിൽ കാര്യങ്ങൾ ചെയ്യുന്നതും ഈ മോഡൽസ് ഡെവലപ്പ് ചെയ്യുന്നതും ഉൾപ്പെടുന്നു. ഇത് ഒരു ഇൻട്രിഗിങ് എക്സ്പീരിയൻസ് ആയിരുന്നു.',\n",
              " 'അപ്പോൾ ഞങ്ങൾ ടീച്ച് ചെയ്യാൻ തുടങ്ങി.',\n",
              " 'ഈ ഐഡിയ ആക്ഷനിലേക്ക് കൊണ്ടുവരാൻ ആഗ്രഹിച്ച ഒരുപാട് ആളുകൾ ഉണ്ടായിരുന്നു.',\n",
              " 'അപ്പോഴാണ് എ ഐ ഫോർ ഭാരത് എന്ന ഐഡിയ തുടങ്ങിയത്, അല്ലേ? ക്വസ്റ്റ്യൻ മാർക്ക് ക്വസ്റ്റ്യൻ മാർക്ക്',\n",
              " 'അപ്പോൾ നമുക്ക് ഈ സിസ്റ്റംസ് ബിൽഡ് ചെയ്യാം.',\n",
              " 'ചിലപ്പോൾ ഈ പ്രോജക്റ്റ്സിന് ഒരുപാട് ഫിനാൻഷ്യൽ സപ്പോർട്ട് വേണം. അതുകൊണ്ട്, ഞങ്ങളുടെ സ്വന്തം കുറച്ച് പൈസ ചിലവഴിച്ചു തുടങ്ങാൻ ഞങ്ങൾ തീരുമാനിച്ചു. എക്സ്റ്റേണൽ ഫണ്ടിങ്ങിനു വേണ്ടി വെയ്റ്റ് ചെയ്യാതെ, ഞങ്ങൾ പണി തുടങ്ങി.',\n",
              " 'അത് ഇൻട്രെസ്റ്റിങ്\\u200cലി ആയിട്ട് ഇവോൾവ് ചെയ്തു.',\n",
              " 'തുടക്കത്തിൽ ഞങ്ങൾ ഒരുപാട് യൂസ് കേസസിനെ കുറിച്ച് ചിന്തിക്കാൻ തുടങ്ങി.',\n",
              " 'ഐ ഐ ടി മദ്രാസിൽ സ്റ്റുഡൻ്റ്സ് ഹെൽമെറ്റ്സിൽ ക്യാമറാസ് ഒട്ടിച്ചിട്ട് കമ്പ്യൂട്ടർ വിഷൻ പ്രോജക്ട്സിൽ വർക്ക് ചെയ്തിരുന്നത് എനിക്കോർമ്മയുണ്ട്.',\n",
              " 'മറ്റു ചിലർ വേറെ കാര്യങ്ങൾ ചെയ്യുന്നുണ്ടായിരുന്നു.',\n",
              " 'അതിനുശേഷം, നമുക്ക് ഒരു സ്പെസിഫിക് ഏരിയ ഓഫ് ഇൻട്രസ്റ്റ് വേണമെന്ന് തീരുമാനിച്ചു. ഇന്ത്യൻ ലാംഗ്വേജസിൽ കോൺസെൻട്രേറ്റ് ചെയ്യാൻ തീരുമാനിച്ചു, കാരണം അവ നമുക്ക് വളരെ പ്രധാനമാണ്.',\n",
              " 'പല ലാംഗ്വേജസ് സംസാരിക്കുന്ന ഒരു രാജ്യത്ത്, ട്രാൻസ്ലേഷന് മോഡൽസ് ഉണ്ടാക്കാൻ ഞങ്ങൾ തീരുമാനിച്ചു.',\n",
              " 'ഞങ്ങൾക്ക് കുറച്ച് കാര്യങ്ങൾ ചെയ്യാൻ പറ്റി. ഒരു ഗ്രൂപ്പ് ഓഫ് സ്റ്റുഡൻ്റ്സ് ഓപ്പൺ സോഴ്സ് സോഫ്റ്റ്\\u200cവെയർ യൂസ് ചെയ്ത് ട്രാൻസ്\\u200cലേഷൻ മോഡൽസ് ഉണ്ടാക്കി. ഈ മോഡൽസ്, ലാർജ് ടെക്നോളജി കമ്പനീസ് അവരുടെ പ്രൊപ്രൈറ്ററി സോഫ്റ്റ്\\u200cവെയർ യൂസ് ചെയ്ത് ഉണ്ടാക്കുന്നതിനേക്കാൾ നല്ലതോ, അല്ലെങ്കിൽ അതിനേക്കാൾ നല്ലതോ ആയിരുന്നു.',\n",
              " 'ലോകത്തിൽ ഏറ്റവും കൂടുതൽ ഇംഗ്ലീഷ് ലാംഗ്വേജ് കണ്ടൻ്റ് ഉപയോഗിക്കുന്നത് ഇന്ത്യ ആയിരിക്കും.',\n",
              " 'ഒരു കാര്യത്തിൽ ഞങ്ങൾ വളരെ ഡൈവേഴ്സ് ആണ്.',\n",
              " 'ഇംഗ്ലീഷ് ലാംഗ്വേജിൽ നിന്നുള്ള നേട്ടങ്ങൾക്ക് വേണ്ടി ഞങ്ങൾ ഇംഗ്ലീഷ് ലാംഗ്വേജ് മോഡൽസ് ഉപയോഗിക്കുന്നുണ്ട്, പക്ഷേ ഇന്ത്യൻ ലാംഗ്വേജസിലെ കണ്ടൻ്റിൽ താൽപ്പര്യമുള്ള ഒരു വലിയ കൂട്ടം ആളുകൾ ഞങ്ങളുടെ കൂടെയുണ്ട്.',\n",
              " 'ഇന്ത്യൻ ലാംഗ്വേജസിലെ ന്യൂസ് ചാനൽസിൻ്റെ വ്യൂവർഷിപ്പ് നോക്കിയാൽ അത് വളരെ സിഗ്\\u200cനിഫിക്കൻ്റ് ആണെന്ന് മനസ്സിലാകും.',\n",
              " 'ഇന്നും ഒരുപാട് സർവൈവിങ് ഇന്ത്യൻ ലാംഗ്വേജ് പ്രിൻ്റ് ന്യൂസ്പേപ്പേഴ്സ് ഉണ്ട്.',\n",
              " 'ലാംഗ്വേജസ് നിലനിൽക്കും, പക്ഷേ ലേറ്റസ്റ്റ് ടെക്നോളജിയിലേക്ക് എപ്പോഴും അപ്ഡേറ്റ് ചെയ്യണം.',\n",
              " 'ഈ സിറ്റുവേഷനിൽ, ഈ ലാംഗ്വേജസ് കംബൈൻ ചെയ്യാനും ചേഞ്ചിങ് എ ഐ എൻവയൺമെൻ്റുമായി കണക്ട് ചെയ്യാനും ആവശ്യമായ ചില ടെക്നോളജീസ് ഞങ്ങളുടെ കൈവശമില്ലായിരുന്നു.',\n",
              " 'അപ്പോൾ ആ ഓപ്പർച്യുണിറ്റി ആയിരുന്നു.',\n",
              " 'യൂസ് കേസ് ലെവലിൽ ഒരുപാട് ഇംപ്രൂവ്മെൻ്റ് വേണമെന്നുണ്ട്. നല്ലപോലെ പെർഫോം ചെയ്യുന്ന മോഡൽസിനെ എങ്ങനെ കൂടുതൽ പ്രാക്ടിക്കൽ ആക്കി, യൂസറിന് കൂടുതൽ ബെനിഫിഷ്യൽ ആക്കി മാറ്റാം എന്നതാണ് ഇതിനർത്ഥം.',\n",
              " 'സ്പെസിഫിക് യൂസ് കേസസിൽ ഫോക്കസ് ചെയ്യുന്ന, പ്രൈവറ്റ്\\u200cലി ഫണ്ടഡ് ആയിട്ടുള്ള ഇന്നൊവേറ്റീവ് വർക്ക് കൂടുതലും നടക്കണമെന്ന് ഞാൻ വിശ്വസിക്കുന്നു.',\n",
              " 'അതുപോലെ തന്നെ കൂടുതൽ ഡീപ് ലെയേഴ്സ് ബിൽഡിങ് ബ്ലോക്ക്സ് ആയിട്ട് മാറും.',\n",
              " 'ഈ ലെയേഴ്സിനെ സ്വന്തം ജോലിക്ക് ഒരു ഫൗണ്ടേഷൻ ആയി യൂസ് ചെയ്യാൻ പറ്റുമെന്നുള്ള കോൺഫിഡൻസ് ആളുകളിൽ വർദ്ധിപ്പിക്കുക എന്നതാണ് മെയിൻ ഗോൾ എന്നാണ് ഞാൻ വിശ്വസിക്കുന്നത്.',\n",
              " 'അപ്പോൾ, ഒരു ഡെവലപ്പറെയോ അല്ലെങ്കിൽ ഒരു സ്മാൾ സ്റ്റാർട്ടപ്പിനെയോ ഒന്ന് ഇമാജിൻ ചെയ്യാം, \"നമ്മുടെ ആപ്പിൽ ഒരു വോയ്\\u200cസ് സിസ്റ്റം ആഡ് ചെയ്യാം\" എന്ന് ആലോചിക്കുന്നത്.',\n",
              " 'അവരുടെ ഓപ്പൺ സോഴ്സ് കോമ്പോണന്റ്സ് സിഗ്നിഫിക്കൻ്റ്ലി ഗ്രോ ആയെങ്കിൽ പോലും ഇത് അച്ചീവ് ചെയ്യാനും ത്രൈവ് ചെയ്യാനുമുള്ള കപ്പാസിറ്റി.',\n",
              " 'അതുകൊണ്ട് നമുക്ക് ഇത് അച്ചീവ് ചെയ്യാൻ പറ്റുമെന്ന് നാട്ടിൽ ഒരു ഷെയേഡ് ഫീലിങ് ഉണ്ടെന്ന് ഞാൻ വിശ്വസിക്കുന്നു.',\n",
              " 'ഇന്ത്യയുടെ ഫ്യൂച്ചറിന് വേണ്ടി കണ്ടിന്യൂസ്\\u200cലി ഗ്രോ ചെയ്യാനും ഇമ്പ്രൂവ് ചെയ്യാനും കഴിയുന്ന ഒരു ടാലന്റ് പൂൾ ഡെവലപ്പ് ചെയ്യുന്നത് വളരെ ക്രൂഷ്യൽ ആണെന്ന് ഞാൻ വിശ്വസിക്കുന്നു.',\n",
              " 'നമ്മൾ ഒരുപാട് ചാലഞ്ചസ് നേരിടുന്ന ഒരു സിറ്റുവേഷനിലാണ്.',\n",
              " 'ഇതിൽ ഒരുപാട് പ്രോബ്ലംസ് ജനറേറ്റീവ് എ ഐ ഉപയോഗിച്ച് അഡ്രസ് ചെയ്യാൻ പറ്റും. എല്ലാത്തിനും പറ്റില്ല, പക്ഷേ ഒരു സിഗ്\\u200cനിഫിക്കന്റ് നമ്പറിന്. ഉദാഹരണത്തിന്, ഇൻഫർമേഷൻ, എഡ്യൂക്കേഷൻ, ഹെൽത്ത്കെയറിൽ ഇനിഷ്യൽ സപ്പോർട്ട് ഒക്കെ ആക്സസ് ചെയ്യാൻ പറ്റും.',\n",
              " 'നമ്മുടെ നാട്ടിൽ ജനറേറ്റീവ് എ ഐ യൂസ് ചെയ്യാൻ ഒരുപാട് ഓപ്പർച്യുണിറ്റീസ് ഉണ്ടെന്ന് ഞാൻ വിശ്വസിക്കുന്നു.',\n",
              " 'ഈ കോൺടെക്സ്റ്റിൽ ഒരു സിഗ്\\u200cനിഫിക്കന്റ് പ്ലെയർ എന്ന നിലയിൽ ഇന്ത്യക്ക് കോൺഫിഡൻസ് ഉണ്ടായിരിക്കണമെന്നാണ് ഞാൻ വിശ്വസിക്കുന്നത്.',\n",
              " 'താങ്കളുടെ മോഡൽസിനെ ആദ്യം മുതൽ ട്രെയിൻ ചെയ്യാനുള്ള കേപ്പബിലിറ്റി ആണ് ഒരു കീ ഫീച്ചർ.',\n",
              " 'ഈ ഗോൾ അച്ചീവ് ചെയ്യാൻ വേണ്ടി ലാർജ് ഗ്രൂപ്പ് ഓഫ് സ്കിൽഡ് പീപ്പിൾ ഉള്ളത് ഒരു ബേസിക് റിക്വയർമെൻ്റ് ആണെന്ന് ഞാൻ വിശ്വസിക്കുന്നു.',\n",
              " 'ഒരു പുതിയ മോഡൽ ഉണ്ടാക്കുന്നതിന് പുറമേ, ലഭ്യമായ ഏതെങ്കിലും എക്സിസ്റ്റിങ് മോഡൽ ഉപയോഗിക്കാം. ഇത് ഒരു കൊമേഴ്\\u200cഷ്യൽ മോഡൽ ആകാം, അല്ലെങ്കിൽ ഒരു ഓപ്പൺ സോഴ്\\u200cസ് മോഡൽ ആകാം.',\n",
              " 'പക്ഷേ ഒരു ക്രൂഷ്യൽ പാർട്ട് ഞാൻ ശ്രദ്ധിക്കുന്നത് എ ഐ എഫ്, ഭാരത്, മറ്റു ഗവൺമെൻ്റ് ഇനിഷ്യേറ്റീവ്സ് ഒക്കെ ചെയ്തുകൊണ്ടിരിക്കുന്ന വർക്ക് ആണ്. ഈ വർക്ക് എക്സെപ്ഷണൽ ആണെന്ന് ഞാൻ വിശ്വസിക്കുന്നു കാരണം കൂടുതൽ ആളുകൾക്ക് ഈ ടെക്നോളജിയുടെ ക്രിയേറ്റേഴ്സ് ആകാൻ ആവശ്യമായ എനർജി ഇത് കൊടുക്കുന്നു.',\n",
              " 'അത് മാത്രമേ വഴിയുള്ളൂ എന്ന് ഞാൻ കരുതുന്നു.',\n",
              " 'ഇന്ത്യൻ പ്ലാറ്റ്\\u200cഫോമുകൾ ഉണ്ടെങ്കിൽ, അതിൽ ഇന്ത്യൻ ബിസിനസ് ഓണേഴ്\\u200cസ് ക്രിയേറ്റ് ചെയ്യുന്നുണ്ടെങ്കിൽ, പെഴ്\\u200cസ്യു ചെയ്യാൻ ആവശ്യത്തിന് വലിയ ഗ്രൂപ്പ് ഉണ്ടാകും.',\n",
              " 'പക്ഷേ ഇന്ത്യ ഈ ടെക്നോളജി അഡോപ്റ്റ് ചെയ്യുന്നതിൽ മുൻപന്നിൽ ഉണ്ടാകുമെന്ന് ഞാൻ വളരെ ഒപ്റ്റിമിസ്റ്റിക് ആണ്.']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# def remove_commas_from_texts(data_list):\n",
        "#     for item in data_list:\n",
        "#         # Remove all commas from the 'text' string\n",
        "#         item['text'] = item['text'].replace(',', '')\n",
        "#     return data_list\n",
        "\n",
        "# updated_texts = remove_commas_from_texts(mal_texts)\n",
        "# updated_texts\n",
        "\n",
        "import re\n",
        "\n",
        "def reduce_question_marks(texts):\n",
        "    \"\"\"\n",
        "    Replaces sequences of multiple question marks with a single question mark.\n",
        "\n",
        "    Args:\n",
        "        text : The input string list.\n",
        "\n",
        "    Returns:\n",
        "        str: Modified string with only one '?' per sequence.\n",
        "    \"\"\"\n",
        "    preproc_text = []\n",
        "    for text in texts:\n",
        "        text = re.sub(r'\\?{2,}', '?', text)\n",
        "        text = re.sub(r'ക്വസ്റ്റ്യൻ മാർക്ക്', '', text)\n",
        "        preproc_text.append(text)\n",
        "    return preproc_text\n",
        "\n",
        "translated_texts = reduce_question_marks(translated_texts)\n",
        "translated_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMWdDLI2aH8Z"
      },
      "source": [
        "## Text-to-Speech using Sarvam BulbulV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTGS5zP6ku9W",
        "outputId": "c30d153d-03fc-45ac-b786-70b4eb296b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1\n",
            "Processed batch 2\n",
            "Processed batch 3\n",
            "Processed batch 4\n",
            "Processed batch 5\n",
            "Processed batch 6\n",
            "Processed batch 7\n",
            "Processed batch 8\n",
            "Processed batch 9\n",
            "Processed batch 10\n",
            "Processed batch 11\n",
            "Processed batch 12\n",
            "Processed batch 13\n",
            "Processed batch 14\n",
            "Processed batch 15\n",
            "Processed batch 16\n",
            "Processed batch 17\n",
            "Processed batch 18\n",
            "Processed batch 19\n",
            "Processed batch 20\n",
            "Processed batch 21\n",
            "Processed batch 22\n",
            "Processed batch 23\n",
            "Processed batch 24\n",
            "Processed batch 25\n",
            "Processed batch 26\n",
            "Processed batch 27\n",
            "Processed batch 28\n",
            "Processed batch 29\n",
            "Processed batch 30\n",
            "Processed batch 31\n",
            "Processed batch 32\n",
            "Processed batch 33\n",
            "Processed batch 34\n",
            "Processed batch 35\n",
            "Processed batch 36\n",
            "Processed batch 37\n",
            "Processed batch 38\n",
            "Processed batch 39\n",
            "Processed batch 40\n",
            "Processed batch 41\n",
            "Processed batch 42\n",
            "Processed batch 43\n",
            "Processed batch 44\n",
            "Processed batch 45\n",
            "Processed batch 46\n",
            "Processed batch 47\n",
            "Processed batch 48\n"
          ]
        }
      ],
      "source": [
        "stretched_audio, raw_audio = client.convert_text_to_speech(\n",
        "    translated_texts,\n",
        "    target_language_code=\"ml-IN\",\n",
        "    model=\"bulbul:v2\",\n",
        "    speaker=\"karun\",\n",
        "    pitch=-0.1,\n",
        "    pace=1.164,\n",
        "    loudness=1.4,\n",
        "    speech_sample_rate=24000,\n",
        ")\n",
        "# stretch_audio is speed controlled to fit the video duration\n",
        "# raw_audio is the raw data got from TTS api, not speed controlled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngUV97WknWuK",
        "outputId": "ddcb5d05-e1d7-41ec-bbe8-73c3244ea412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/output_data/raw_output_audio.wav'>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sure the directory exists before downloading\n",
        "os.makedirs(OUTPUT_AUDIO_PATH, exist_ok=True)\n",
        "\n",
        "# Export the combined audio to a file\n",
        "# stretched_audio.export(OUTPUT_AUDIO_FILE, format=\"wav\")\n",
        "raw_audio.export(RAW_OUTPUT_AUDIO_FILE, format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r90H7JqEhz_9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display\n",
        "\n",
        "# Display separated tracks\n",
        "display(\n",
        "    # Audio(OUTPUT_AUDIO_FILE, autoplay=False),\n",
        "    Audio(RAW_OUTPUT_AUDIO_FILE, autoplay=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf_wwJPraPIO"
      },
      "source": [
        "## Reassembling and Merging Audio and Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgS835emachG"
      },
      "source": [
        "### Removing audio from the original input video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9wWcNW721iI",
        "outputId": "56e18b56-9abe-4bcf-81c0-44970eb068e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/       \u001b[01;34moutput_data\u001b[0m/         \u001b[01;34mpretrained_models\u001b[0m/  \u001b[01;34mtext_data\u001b[0m/\n",
            "\u001b[01;34minput_data\u001b[0m/  \u001b[01;34mpreprocessed_audio\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'input_data/input_video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:04:23.83, start: 0.000000, bitrate: 6804 kb/s\n",
            "  Stream #0:0(und): Video: vp9 (Profile 0) (vp09 / 0x39307076), yuv420p(tv, bt709), 3840x2160, 6672 kb/s, 25 fps, 25 tbr, 16k tbn, 16k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 05/22/2025.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Output #0, mp4, to 'muted_video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: vp9 (Profile 0) (vp09 / 0x39307076), yuv420p(tv, bt709), 3840x2160, q=2-31, 6672 kb/s, 25 fps, 25 tbr, 16k tbn, 16k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 05/22/2025.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame= 6595 fps=4504 q=-1.0 Lsize=  214885kB time=00:04:23.76 bitrate=6674.0kbits/s speed= 180x    \n",
            "video:214855kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.014042%\n"
          ]
        }
      ],
      "source": [
        "%ls\n",
        "!ffmpeg -i input_data/input_video.mp4 -an -c:v copy muted_video.mp4 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix_4l8rVult0"
      },
      "outputs": [],
      "source": [
        "# Display the input video\n",
        "Video('muted_video.mp4', width=640, height=360, embed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6mwyIgdahke"
      },
      "source": [
        "### Adding the dubbed audio to the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkUkaTFg1IPo",
        "outputId": "86dc1717-2232-47bf-e290-bfe197f3e0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'muted_video.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:04:23.80, start: 0.000000, bitrate: 6673 kb/s\n",
            "  Stream #0:0(und): Video: vp9 (Profile 0) (vp09 / 0x39307076), yuv420p(tv, bt709), 3840x2160, 6672 kb/s, 25 fps, 25 tbr, 16k tbn, 16k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 05/22/2025.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
            "\u001b[0mInput #1, wav, from 'output_data/raw_output_audio.wav':\n",
            "  Duration: 00:04:20.89, bitrate: 384 kb/s\n",
            "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp4, to 'output_wo_bgm.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: vp9 (Profile 0) (vp09 / 0x39307076), yuv420p(tv, bt709), 3840x2160, q=2-31, 6672 kb/s, 25 fps, 25 tbr, 16k tbn, 16k tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 05/22/2025.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 24000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame= 6523 fps=2404 q=-1.0 Lsize=  215655kB time=00:04:20.88 bitrate=6771.9kbits/s speed=96.2x    \n",
            "video:213338kB audio:2208kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.050228%\n",
            "\u001b[1;36m[aac @ 0x55e3c12dcb00] \u001b[0mQavg: 126.367\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -i muted_video.mp4 -i output_data/raw_output_audio.wav -c:v copy -map 0:v:0 -map 1:a:0 -shortest output_wo_bgm.mp4 -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH3VhcrVapkC"
      },
      "source": [
        "### Adding the accompaniment audio to the final output video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR2gpNCI5jug"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -i output_wo_bgm.mp4 -i preprocessed_audio/accompaniment.wav -filter_complex \"[0:a][1:a]amix=inputs=2:duration=first:dropout_transition=3\" -c:v copy -map 0:v:0 -shortest final_output.mp4 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BqrcHRb437nk"
      },
      "outputs": [],
      "source": [
        "# # Display the final output audio\n",
        "Audio(RAW_OUTPUT_AUDIO_FILE, autoplay=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rr6Kv_yx32qL",
        "outputId": "6a85bc9e-7fb0-4b2c-fd28-902cdf83661d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "# Display the final output video\n",
        "Video('final_output.mp4', width=640, height=360, embed=True)\n",
        "\n",
        "# AUDIO SEEMS LAGGY AS IT WAS STRETCHED TO MEET THE VIDEO LENGTH, PURE DUBBED AUDIO IS AVAILABLE IN THE ABOVE CODE BLOCK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUaOUruMKmU7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rjTjwmBrGo1O",
        "Lbmx18elG9fA",
        "f5q1vREBHJrZ",
        "0_kTCInnJU2a",
        "OAwBYKItxNkc",
        "9FyltOmbWwgB"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}